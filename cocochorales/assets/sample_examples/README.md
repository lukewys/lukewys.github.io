## Data Structures

The dataset contains three parts:

- `main_dataset`: The main dataset consists of mixture MIDI, stems MIDI, mixture audio, stems audio, and metadata.
- `note_expression`: Note expressions generated from MIDI-DDSP note expression generator and after
  manipulation. Those are the note expressions input to the synthesis generator for generating synthesis parameters.
  Please refer to the [MIDI-DDSP paper](https://openreview.net/pdf?id=UseMOjWENv) for more information.
- `synthesis_parameters`: Synthesis parameters generated by MIDI DDSP synthesis generator and after manipulation. Please refer to the [MIDI-DDSP paper](https://openreview.net/pdf?id=UseMOjWENv) for more information.

### Track ID
Each track has its own unique ID. The naming of the tracks follows `<ensemble>_track<id>`. Where `<ensemble>` is one of four ensembles: string, brass, woodwind, random. The ID is a 6-digit number, from 000001 to 240000, where 000001-192000 are training set, 192001-216000 are valid set, and 216001-240000 are test set.

### Data Structure

The data structure for each part of dataset (main_dataset, note_expression, synthesis_parameters) is as follows:

#### Main Dataset

```
string_track000001
   |-- metadata.yaml
   |-- mix.mid
   |-- stems_MIDI
   |    |-- 0_violin.mid
   |    |-- 1_violin.mid
   |    |-- 2_viola.mid
   |    |-- 3_cello.mid 
   |-- mix.wav
   |-- stems_audio
        |-- 0_violin.wav
        |-- 1_violin.wav
        |-- 2_viola.wav
        |-- 3_cello.wav 
```

- `metadata.yaml` contains metadata for each track (see below).
- `mix.mid` is the mixture MIDI file contains all four voices.
- `stems_MIDI` contains MIDI files separated by voice. Their naming follows: `<voice_id(0-index)>_<instrument>.mid`.
- `mix.wav` is the mixture auido.
- `stems_audio `contains the stems audio for each voice. Their naming follows: `<voice_id(0-index)>_<instrument>.wav`.

#### Metadata

The metadata for each piece is stored in yaml. Here is an example:

`brass_track001222.yaml`:

```yaml
midi_file: 233461.mid # The file name (ID) of the MIDI.
tempo: 88 # Tempo of the MIDI.
ensemble: brass # Ensemble of the piece, one of four ensembles: "string, brass, woodwind, random".
instrument_name: # Instrument name. Keys are the voice ID, in 0-3 in the order of SATB.
  0: trumpet
  1: horn
  2: trombone
  3: tuba
midi_program_number: # MIDI program number for each voice. Keys are the voice ID, in 0-3 in the order of SATB.
  0: 56 # The MIDI program number is 0-indexed (start from 0).
  1: 60
  2: 57
  3: 58
normalization_factor: -13.0 # Target normalization [dB] for all stems before lowering gain to avoid clipping, will always be "-13.0".
target_peak: -1.0 # Target peak [dB] when applying gain to all stems after summing mixture, will always be "-1.0".
normalized: true # Whether the mix and stems were normalized according to the ITU-R BS.1770-4 spec, will always be "true".
overall_gain: 0.37353415035486276 # Gain applied to every stem to make sure mixture does not clip when stems are summed.
stem_integrated_loudness: # Integrated loudness [dB] of each voice as calculated by the ITU-R BS.1770-4 spec.
  0: -33.88453138444481 # The voice ID. In 0-3 in the order of SATB.
  1: -30.30338354914199
  2: -36.686212471446865
  3: -38.977449420172086
pitch_correction_amount: # The amount of pitch correction applied to each note. Each row represent a note. 
  0: # The voice ID. In 0-3 in the order of SATB.
  - 0.5417262752492821
  - 0.5238033268006898
  - 0.45279361002894647
  - 0.6988713224811681
  - ...
  1:
  - 0.12652192668714468
  - 0.4198836882340933
  - 0.1115024018823354
  - 0.6942255304145393
  - 0.6866081981008881
  - ...
  2:
  - ...
  3:
  - ...
```

#### Note Expression

The note expression is saved as a csv for each voice. They are named under the same rule as `stems_MIDI` and `stems_audio` in main dataset. (`<voice_id(0-index)>_<instrument>.mid`)

 In each csv, each row represents a note (including the rest note). The first 6 columns are the 6 note expressions from 0 to 1 for each note defined in [MIDI-DDSP paper](https://openreview.net/pdf?id=UseMOjWENv). The rest of the columns record the note pitch and duration information. The pitch is in MIDI pitch number, and the onset, offset and note_length are in number of frames where each frame is 4ms.

| **volume**         | **vol_fluc**        | **vol_peak_pos**    | **vibrato**         | **brightness**     | **attack**         | **pitch** | **onset** | **offset** | **note_length** |
| ------------------ | ------------------- | ------------------- | ------------------- | ------------------ | ------------------ | --------- | --------- | ---------- | --------------- |
| 0.0                | 0.0                 | 0.0                 | 0.0                 | 0.0                | 0.0                | 0         | 0         | 0          | 0               |
| 0.7395809888839720 | 0.33552518486976600 | 0.34789690375328100 | 0.32672226428985600 | 0.5702816247940060 | 0.55987149477005   | 77        | 0         | 168        | 168             |
| 0.0                | 0.0                 | 0.0                 | 0.0                 | 0.0                | 0.0                | 0         | 168       | 173        | 5               |
| 0.7533653974533080 | 0.2437175065279010  | 0.27141907811164900 | 0.304775208234787   | 0.5326902270317080 | 0.6773836612701420 | 79        | 173       | 331        | 158             |
| 0.6803067922592160 | 0.2552274465560910  | 0.4033176600933080  | 0.3316570520401000  | 0.5263296365737920 | 0.4892987310886380 | 81        | 331       | 672        | 341             |
| 0.0                | 0.0                 | 0.0                 | 0.0                 | 0.0                | 0.0                | 0         | 672       | 679        | 7               |
| 0.7296117544174190 | 0.2627417743206020  | 0.0604700893163681  | 0.2803541421890260  | 0.5160598754882810 | 0.7768481969833370 | 79        | 679       | 762        | 83              |
| 0.767565131187439  | 0.22129236161708800 | 0.07845849543809890 | 0.2821490466594700  | 0.5629626512527470 | 0.7202404141426090 | 77        | 762       | 847        | 85              |
| 0.0                | 0.0                 | 0.0                 | 0.0                 | 0.0                | 0.0                | 0         | 847       | 851        | 4               |
| 0.7466005682945250 | 0.21726730465889000 | 0.16683416068553900 | 0.2967233955860140  | 0.5283809304237370 | 0.7374227643013    | 76        | 851       | 1020       | 169             |
| 0.7064409255981450 | 0.22529537975788100 | 0.34815743565559400 | 0.3333543539047240  | 0.5272674560546880 | 0.5293049812316900 | 74        | 1020      | 1360       | 340             |
| 0.0                | 0.0                 | 0.0                 | 0.0                 | 0.0                | 0.0                | 0         | 1360      | 1362       | 2               |
| ...                | ...                 | ...                 | ...                 | ...                | ...                | ...       | ...       | ...        | ...             |

Note: The MIDI generated from Coconet does not contain rest notes, but we added random expression timing for each note, resulting in rest notes in CSV.



#### Synthesis Parameters

Synthesis parameters for each piece is a pickle file containing a dictionary of numpy arrays:

```
#string_track000001.pickle
{
  0: # The voice ID. In 0-3 in the order of SATB
    {
     'f0_hz': numpy array of shape [num_frames, 1],
     'amplitudes': numpy array of shape [num_frames, 1],
     'harmonic_distribution': numpy array of shape [num_frames, 60],
     'noise_magnitudes': numpy array of shape [num_frames, 65],
    }
  1: ...
 	2: ...
 	3: ...
}
```

The synthesis parameters consist of four synthesis parameters used in [DDSP](https://github.com/magenta/ddsp). Details can be found in [DDSP paper](https://openreview.net/forum?id=B1x1ma4tDr) and [DDSP tutorial](https://github.com/magenta/ddsp/blob/main/ddsp/colab/tutorials/1_synths_and_effects.ipynb).





